---
title: "Word Analysis"
author: "Miha Rupar"
output: 
  github_document:
    toc: true
    toc_depth: 3
---
```{r, include=FALSE,message=FALSE,warning=FALSE}
library(htm2txt)
library(tidyverse)
library(quanteda)
library(quanteda.textplots)
```


## Data import
```{r}
url <- 'http://bos.zrc-sazu.si/sbsj.html'
text <- gettxt(url)
```


## Data procesing
Transforming data to get desired outcome for later use
```{r}
words <- text %>% str_split("\n") %>% 
  as.data.frame() %>% .[-c(1:5), ] %>%
  as.data.frame() %>% slice(., 1:(n() - 5)) 

colnames(words) <- c("besede")

words <- words %>% mutate(
  besede = besede %>%
    str_replace(" \\s*\\([^\\)]+\\)", "") %>%
    str_replace_all("\xc2\xa0", " ")%>%
    str_replace_all("-"," ") %>%
    str_trim("right") %>%
    str_replace_all(" ",".") %>%
    paste0(".")
)
```

## Calculate weight
Defining weight matrix
```{r}
letter <- c("a", "b", "c", "č", "d", "e", "f", "g", "h", "i", "j", "k", "l", 
            "m", "n", "o", "p", "r", "s", "š", "t", "u", "v", "z", "ž",".")
n_letter <- toupper(letter)

weight_mat <- matrix(0, nrow = 26, ncol = 26)
colnames(weight_mat) <- letter
rownames(weight_mat) <- toupper(letter)

```

Function for adding weights to matrix, based on next character in string.
Ex. "abc" => [a,b] +1 & [b,c] +1
```{r}
add_weights <- function(word,lvl){
  if(nchar(word)<lvl+1){return()}
  l1 = substring(toupper(word), 1, lvl)
  l2 = substring(tolower(word), lvl+1, lvl+1)
  if(l1 %in% toupper(n_letter) & l2 %in% tolower(letter)){
    weight_mat[l1, l2] <<- weight_mat[l1, l2] + 1
  }
  add_weights(substring(word, 2),lvl)
}

```


```{r}
filtered_words <- function(word, lvl) {
  l1 <- substring(toupper(word), 1, lvl)
  if(nchar(word) < lvl + 1) {
    return(l1 %in% toupper(n_letter))
  }
  l2 <- substring(tolower(word), lvl + 1, lvl + 1)
  if(l1 %in% toupper(n_letter) && l2 %in% tolower(letter)) {
    return(filtered_words(substring(word, 2), lvl))
  }else {
    return(FALSE)
  }
}

```

```{r}
reset <- function(){
  filtered_mat <- weight_mat
  filtered_mat[filtered_mat < 1500] <- 0
  n_letter <<- c()
  for (i in rownames(filtered_mat)){
    for (j in colnames(filtered_mat)){
      if (filtered_mat[i,j] != 0){
        n_letter <<- c(n_letter,paste0(i,j))
      }
    }
  }
  weight_mat <<- matrix(0, ncol = 26, nrow = length(n_letter))
  colnames(weight_mat) <<- letter
  rownames(weight_mat) <<- toupper(n_letter)
}
```

```{r}
calculate_weights <- function(lvl){
  if(lvl != 1){reset()}
  for (w in 1:nrow(words)){
  if(filtered_words(words$besede[w],lvl)){
    add_weights(words$besede[w],lvl)
    }
  }
}
```


Calculate weights and visualize
```{r}
calculate_weights(1)
heatmap(weight_mat, Colv=NA, Rowv=NA)
```


### Clustering
```{r}
heatmap(weight_mat)
```



## Data filtering
To avoid having too large a matrix when guessing the next letter, let's eliminate letter relations that do not occur offten and with that make our matrix smaller 

### 2
```{r}
calculate_weights(2)
heatmap(weight_mat, Colv=NA, Rowv=NA)
```


### 3
```{r}
calculate_weights(3)
heatmap(weight_mat, Colv=NA, Rowv=NA)
```

### 4
```{r}
calculate_weights(4)
heatmap(weight_mat, Colv=NA, Rowv=NA)
```


### letter co-occurence
```{r}
weight_mat %>% as.dfm() %>%
  fcm() %>% textplot_network()
```

